#!/usr/bin/env perl

use strict;
use warnings;
use 5.012;

use autodie;

use BioX::Seq::Stream;
use BioX::Seq::Fetch;
use Getopt::Long;
use File::Which qw/which/;
use File::Temp qw/tempfile/;
use File::Basename qw/basename/;
use List::Util qw/min max sum shuffle any/;

our $VERSION = 0.001;

# inputs
my $fn_in;
my $sync_in;
# outputs
my $dir_out;
my $sync_out;
my $fn_sif;
# parameters
my $min_cov        = 0.90;
my $max_diff       = 0.35;
my $max_size       = 60;
my $max_sync_size  = 200;
my $min_len        = 100;
my $min_size       = 6;
my $rank_mode      = 'edges';
my $sync_rank_mode = 'none';
my $randomize      = 0;

# global variables
my $ret; #can re-use

my @rank_modes = qw/
    edges
    length
    none
/;

# Use a temporary filename here as a semaphore, even though the actual file is
# not used. This prevents problems with hard-coded temp filenames clashing
# during simultaneous calls ( as happened with previous versions)
my ($tmp_fh, $db_name) = tempfile();
$db_name = basename($db_name);


GetOptions(
    'in=s'             => \$fn_in,
    'sync_in=s'        => \$sync_in,
    'out=s'            => \$dir_out,
    'sync_out=s'       => \$sync_out,
    'sif=s'            => \$fn_sif,
    'min_cov=f'        => \$min_cov,
    'max_diff=f'       => \$max_diff,
    'min_len=i'        => \$min_len,
    'min_size=i'       => \$min_size,
    'max_size=i'       => \$max_size,
    'max_sync_size=i'  => \$max_sync_size,
    'rank_mode=s'      => \$rank_mode,
    'sync_rank_mode=s' => \$sync_rank_mode,
    'randomize'        => \$randomize,
    'version'          => sub{ say $VERSION; exit; },
);

my $DALIGNER = which('daligner')
    // die "daligner not found. Check your DALIGNER install.\n";
my $fasta2DB = which('fasta2DB')
    // die "fasta2DB not found. Check your DAZZ_DB install.\n";
my $LAdump = which('LAdump')
    // die "LAdump not found. Check your DALIGNER install.\n";
my $DBshow = which('DBshow')
    // die "DBshow not found. Check your DAZZ_DB install.\n";

die "Output directory not defined\n"
    if (! defined $dir_out);
die "Output directory exists and is not a directory\n"
    if (-e $dir_out && ! -d $dir_out);
mkdir $dir_out if (! -e $dir_out);
die "Output directory exists and is not a directory\n"
    if (-e $sync_out && ! -d $sync_out);
mkdir $sync_out if (! -e $sync_out);

die "$rank_mode not a valid rank mode\n"
    if (! any {$_ eq $rank_mode} @rank_modes);
die "$sync_rank_mode not a valid sync rank mode\n"
    if (! any {$_ eq $sync_rank_mode} @rank_modes);

die "max_sync_size must be equal to or larger than max_size\n"
    if ($max_sync_size < $max_size);

# rename input sequences to PacBio-like format (for DALIGNER input)
my $tmp_fa   = File::Temp->new(SUFFIX=>'.fasta');

my @seq_lens;
my $prefix;
my $i = 0;

my $p = BioX::Seq::Stream->new($fn_in);

while (my $seq = $p->next_seq) {

    if ($seq->desc =~ /runid=(\w+)/) {
        die "Run ID mismatch\n"
            if (defined $prefix && $prefix ne $1);
        $prefix //= $1;
    }
    $prefix //= 'unknown_run';

    my $new_id = sprintf "%s/%u/0_%u",
        $prefix,
        $i++,
        length($seq),
    ;
    
    $seq->id = $new_id;
    print {$tmp_fa} $seq->as_fasta;
    push @seq_lens, length $seq;

}
close $tmp_fa;


# create DALIGNER database
$ret = system(
    $fasta2DB,
    $db_name,
    $tmp_fa
);
die "fasta2DB failed: $!\n" if ($ret);


# run DALIGNER
$ret = system(
    $DALIGNER,
    "-l$min_len",
    "$db_name.db",
    "$db_name.db",
);
die "daligner failed: $!\n" if ($ret);


$p = BioX::Seq::Fetch->new("$fn_in")
    or die "Error opening $fn_in for parsing: $@\n";
my $p_sync = undef;
if (defined $sync_in) {
    $p_sync = BioX::Seq::Fetch->new("$sync_in")
}

my @seq_ids = $p->ids;
my $n = scalar @seq_ids;

open my $dump, '-|',
    $LAdump,
    '-cdl',
    "$db_name.db",
    "$db_name.db",
    "$db_name.$db_name.las",
;


# parse summary line
chomp( my $h1 = <$dump> );
my ($op, $cat, $val) = split ' ', $h1;
die "Unexpected input format\n"
    if ($op ne '+' || $cat ne 'P');
my $n_aligns = $val;

# ignore second line (for now)
my $h2 = <$dump>;

my @tags = qw/P L C D/;

my $aln = {};

my $graph;


# process alignment blocks
while (my $line = <$dump>) {

    chomp $line;
    my ($cat, @vals) = split ' ', $line;

    # consistency check
    die "unexpected line order\n"
        if ($cat ne $tags[0]);
    push @tags, shift @tags;

    $aln->{$cat} = \@vals;

    # process completed alignment
    if ($cat eq 'D') {
        process_alignment($aln);
        $aln = {};
    }

}


# traverse graph
my %assignments;
my $node_id = 0;

no warnings 'recursion';
for my $key (keys %$graph) {
    my $assigned = traverse($key, $node_id);
    ++$node_id if ($assigned);
}


# write SIF file if necessary
if (defined $fn_sif) {

    my %seen;
    open my $sif, '>', $fn_sif;
    for my $x (keys %$graph) {

        for my $y (keys %{ $graph->{$x} }) {

            next if ($seen{"$x.$y"});
            next if ($seen{"$y.$x"});
            $seen{"$x.$y"} = 1;
            say {$sif} join "\t",
                $x,
                'aln',
                $y,
            ;

        }

    }
    close $sif;

}
        

my %counts;
my %link_cutoffs;
my %delta_cutoffs;
my %sync_link_cutoffs;
my %sync_delta_cutoffs;
my %written;
my %sync_written;
my %fhs;
my %fhs_sync;
my %all_lens;
my %used_lens;
my %medians;

# randomize input order if asked
my @keys = $randomize
    ? shuffle keys %assignments
    : sort {$a <=> $b} keys %assignments;

# $key is the 0-based read index
for my $key (@keys) {

    my $clust = $assignments{$key};

    # generate missing cluster counts
    my @members;
    if (! defined $counts{$clust}) {
        @members = grep {$assignments{$_} == $clust} keys %assignments;
        $counts{$clust} = scalar @members;
    }

    # short-circuit if cluster too small
    next if ($counts{$clust} < $min_size);

    # generate missing linkage cutoffs:
    # when subsampling, nodes with higher numbers of links to other cluster
    # nodes can be given priority
    if (! defined $link_cutoffs{$clust}) {
        my @links   = map {scalar keys %{ $graph->{$_} } } @members;
        @links = sort {$b <=> $a} @links;

        my $n = $counts{$clust} > $max_size ? $max_size : $counts{$clust};
        $link_cutoffs{$clust} = $links[$n-1];
        $n = $counts{$clust} > $max_sync_size ? $max_sync_size : $counts{$clust};
        $sync_link_cutoffs{$clust} = $links[$n-1];
    }

    # generate missing delta cutoffs:
    # when subsampling, nodes with length closer to the cluster median
    # can be given priority
    if (! defined $delta_cutoffs{$clust}) {
        my @lens = sort {$a <=> $b} map {$seq_lens[$_]} @members;
        my $median = median(@lens);
        $medians{$clust} = $median;
        my @deltas = sort {$a <=> $b} map {abs($_-$median)} @lens;

        my $n = $counts{$clust} > $max_size ? $max_size : $counts{$clust};
        $delta_cutoffs{$clust} = $deltas[$n-1];
        $n = $counts{$clust} > $max_sync_size ? $max_sync_size : $counts{$clust};
        $sync_delta_cutoffs{$clust} = $deltas[$n-1];
    }

    if (! defined $fhs{$clust}) {
        my $fn_out = sprintf "%s/cluster_%0*u.fasta",
            $dir_out,
            length($node_id),
            $clust;
        open my $fh, '>', $fn_out;
        $fhs{$clust} = $fh;

        # open sync handles if needed
        if (defined $p_sync) {
            my $fn_out = sprintf "%s/cluster_%0*u.fasta",
                $sync_out,
                length($node_id),
                $clust;
            open my $fh, '>', $fn_out;
            $fhs_sync{$clust} = $fh;
        }
            
    }

    push @{ $all_lens{$clust} }, $seq_lens[$key];

    # All of these filters are applied BEFORE sync files are written
    my $write_sync = 1;
    if ($sync_rank_mode eq 'edges') {
        # skip if linkage count < cutoff
        my $n_links = scalar keys %{ $graph->{$key} };
        $write_sync = 0
            if ($n_links < $sync_link_cutoffs{$clust});
    }
    elsif ($sync_rank_mode eq 'length') {
        # skip if linkage count < cutoff
        my $delta = abs($seq_lens[$key] - $medians{$clust});
        $write_sync = 0
            if ($delta > $sync_delta_cutoffs{$clust});
    }
    # skip if sync max size already reached.
    $write_sync = 0
        if (defined $sync_written{$clust}
            && $sync_written{$clust} >= $max_sync_size);

    if (defined $p_sync && $write_sync) {

        my $fh = $fhs_sync{$clust};
        my $id = $seq_ids[$key];
        my $seq = $p_sync->fetch_seq($id)
            // die "Failed to fetch sequence $id: $@\n";
        print {$fh} $seq->as_fasta;
        ++$sync_written{$clust};

    }

    # All of these filters are applied AFTER sync files are written
    if ($rank_mode eq 'edges') {
        # skip if linkage count < cutoff
        my $n_links = scalar keys %{ $graph->{$key} };
        next if ($n_links < $link_cutoffs{$clust});
    }
    elsif ($rank_mode eq 'length') {
        # skip if linkage count < cutoff
        my $delta = abs($seq_lens[$key] - $medians{$clust});
        next if ($delta > $delta_cutoffs{$clust});
    }

    # skip if cluster max size already reached.
    next if (defined $written{$clust} && $written{$clust} >= $max_size);

    my $fh = $fhs{$clust};
    my $id = $seq_ids[$key];
    my $seq = $p->fetch_seq($id)
        // die "Failed to fetch sequence $id: $@\n";
    push @{ $used_lens{$clust} }, $seq_lens[$key];
    print {$fh} $seq->as_fasta;
    ++$written{$clust};
    
}

close $_ for (values %fhs);
close $_ for (values %fhs_sync);

say join "\t", qw/
    node_id
    read_count
    mean_length
    min_length
    max_length
    mean_used_length
    min_used_length
    max_used_length
/;

for my $node (sort {$counts{$b} <=> $counts{$a}} keys %counts) {
    my @stats = $counts{$node} >= $min_size
        ? ( sprintf("%0.1f",sum(@{$all_lens{$node}})/scalar(@{$all_lens{$node}})),
            min(@{$all_lens{$node}}),
            max(@{$all_lens{$node}}),
            sprintf("%0.1f",sum(@{$used_lens{$node}})/scalar(@{$used_lens{$node}})),
            min(@{$used_lens{$node}}),
            max(@{$used_lens{$node}}),
          )
        : qw/NA NA NA NA NA NA/;
    say join "\t",
        sprintf("cluster_%0*u", length($node_id), $node),
        $counts{$node},
        @stats,
    ;
}

unlink "$tmp_fa";

exit;

sub traverse {

    my ($key, $node) = @_;
    return 0 if (defined $assignments{$key});
    $assignments{$key} = $node;
    my $n = 1;
    for my $key2 (keys %{ $graph->{$key} }) {
        $n += traverse($key2, $node);
    }
    return $n;

}



sub process_alignment {

    my ($aln) = @_;

    my $n1 = $aln->{P}->[0] - 1;
    my $n2 = $aln->{P}->[1] - 1;

    if ($n1 > $#seq_ids) {
        die "N1 $n1 out of range\n";
    }
    if ($n2 > $#seq_ids) {
        die "N2 $n2 out of range\n";
    }

    my $l1 = $aln->{L}->[0];
    my $l2 = $aln->{L}->[1];

    return if ($l1 < $min_len);
    return if ($l2 < $min_len);

    my @crd = @{ $aln->{C} };
    my $al1 = $crd[1] - $crd[0];
    my $al2 = $crd[3] - $crd[2];

    return if ($al1 / $l1 < $min_cov);
    return if ($al2 / $l2 < $min_cov);

    my $d = $aln->{D}->[0] / ($al1+$al2) * 2;
    return if ($d > $max_diff);

    # register edge
    $graph->{$n1}->{$n2} = 1;

    return;

}

sub median {

    my $n = scalar @_;
    return ($n%2 == 1)
        ? $_[$n/2]
        : sum( @_[ ($n/2-1)..($n/2) ] )/2;

}
